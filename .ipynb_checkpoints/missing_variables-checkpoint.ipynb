{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz System with Missing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Simulating the Lorenz system.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lorenz import Lorenz\n",
    "\n",
    "# --> Sets the parameters to their classical values.\n",
    "sigma, rho, beta = 10., 28., 8./3.\n",
    "\n",
    "# --> Integration time.\n",
    "t = np.linspace(0, 20, 2000)\n",
    "\n",
    "# --> Produce the date to be used in the sparse identification.\n",
    "x0 = np.array([-8., 7., 27.]) # Initial condition.\n",
    "x, dx = Lorenz(x0, sigma, rho, beta, t)\n",
    "\n",
    "# --> Slightly different initial condition to highlight the chaotic nature.\n",
    "y0 = np.array([-8.01, 7., 27.]) # Initial condition.\n",
    "y, dy = Lorenz(y0, sigma, rho, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Plot time traces of the two trajectories as well as the corresponding stange attractor.\n",
    "w = 10\n",
    "fig = plt.figure(figsize=(1.5*w, w/2))\n",
    "gs = GridSpec(3, 6)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, :3])\n",
    "ax0.plot(t, x[:, 0])\n",
    "ax0.plot(t, y[:, 0])\n",
    "ax0.set_ylabel('x')\n",
    "ax0.set_xticks([])\n",
    "ax0.set_xlim(0, 20)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1, :3])\n",
    "ax1.plot(t, x[:, 1])\n",
    "ax1.plot(t, y[:, 1])\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xlim(0, 20)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2, :3])\n",
    "ax2.plot(t, x[:, 2])\n",
    "ax2.plot(t, y[:, 2])\n",
    "ax2.set_ylabel('z')\n",
    "ax2.set_xlabel('t')\n",
    "ax2.set_xlim(0, 20)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:, 3:], projection='3d')\n",
    "ax3.plot(x[:, 0], x[:, 1], x[:, 2])\n",
    "ax3.plot(y[:, 0], y[:, 1], y[:, 2])\n",
    "ax3.set_xlabel('x', labelpad=10)\n",
    "ax3.set_ylabel('y')\n",
    "ax3.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Creation of the library Theta.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "library = PolynomialFeatures(degree=2, include_bias=True)\n",
    "Theta = library.fit_transform(x)\n",
    "n_lib = library.n_output_features_\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "A = block_diag(Theta, Theta, Theta)\n",
    "b = dx.flatten(order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Sequentially hard-thresholded estimator.\n",
    "from sparse_identification import sindy\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "shols = sindy(l1=0.01, solver='lstsq')\n",
    "\n",
    "# --> Fit the OLS model.\n",
    "shols.fit(A, b)\n",
    "print('Total number of possible terms :', shols.coef_.size)\n",
    "print('Number of non-zero coefficients :', np.count_nonzero(shols.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identified equation for x : \\n\")\n",
    "print(shols.coef_[:n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[n_lib:2*n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[2*n_lib:3*n_lib], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "library = PolynomialFeatures(degree=5, include_bias=True)\n",
    "Theta = library.fit_transform(x_trunc)\n",
    "n_lib = library.n_output_features_\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "A_trunc = block_diag(Theta, Theta)\n",
    "b_trunc = dx_trunc.flatten(order='F')\n",
    "\n",
    "shols_trunc = sindy(l1=0.01, solver='lstsq')\n",
    "\n",
    "# --> Fit the OLS model to truncated data\n",
    "shols_trunc.fit(A_trunc, b_trunc)\n",
    "print('Total number of possible terms :', shols_trunc.coef_.size)\n",
    "print('Number of non-zero coefficients :', np.count_nonzero(shols_trunc.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identified equation for x : \\n\")\n",
    "print(shols.coef_[:n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[n_lib:2*n_lib], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Algorithm for Missing Variables applied to Lorenz System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Simulating the Lorenz system.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lorenz import Lorenz\n",
    "\n",
    "# --> Sets the parameters to their classical values.\n",
    "sigma, rho, beta = 10., 28., 8./3.\n",
    "\n",
    "# --> Integration time.\n",
    "t = np.linspace(0, 20, 2000)\n",
    "\n",
    "# --> Produce the date to be used in the sparse identification.\n",
    "x0 = np.array([-8., 7., 27.]) # Initial condition.\n",
    "x, dx = Lorenz(x0, sigma, rho, beta, t)\n",
    "\n",
    "# --> Slightly different initial condition to highlight the chaotic nature.\n",
    "y0 = np.array([-8.01, 7., 27.]) # Initial condition.\n",
    "y, dy = Lorenz(y0, sigma, rho, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "dt = t[1] - t[0]\n",
    "degree = 2\n",
    "num_coeffs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to zero\n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def f(x):\n",
    "    global iter_num\n",
    "    coeffs = x[:3*num_coeffs]\n",
    "    z = x[3*num_coeffs:]\n",
    "    dz = derivative(z, dt=dt)\n",
    "    z = z.reshape(1, z.shape[0]) # reshape so we can concatenate with x_trunc\n",
    "    library = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    x_est = np.concatenate((x_trunc, z.T), axis=1)\n",
    "    Theta = library.fit_transform(x_est)\n",
    "    A = block_diag(Theta, Theta, Theta)\n",
    "    dx_est = np.concatenate((dx_trunc, dz), axis=1)\n",
    "    dx_est = dx_est.ravel()\n",
    "    rows = A @ coeffs - dx_est\n",
    "    if iter_num % 50000 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, np.sum(rows ** 2)))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return np.sum(rows ** 2)\n",
    "\n",
    "res = minimize(f, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import basinhopping\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to one\n",
    "l1 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "res = basinhopping(f, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Algorithm for Missing Variables applied to Lotka-Volterra System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lotka_Volterra import Lotka_Volterra\n",
    "\n",
    "alpha = np.array([1, -1, -1])\n",
    "beta = np.array([[0, -1, 0], [1, 0, -1], [0, 1, 0]])\n",
    "t = np.linspace(0, 5, 2000)\n",
    "x0 = np.array([0.5, 1, 2]) # Initial condition.\n",
    "x, dx = Lotka_Volterra(x0, alpha, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "dt = t[1] - t[0]\n",
    "l1 = 0.01\n",
    "degree = 2\n",
    "num_coeffs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to zero\n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def f(x):\n",
    "    global iter_num\n",
    "    coeffs = x[:3*num_coeffs]\n",
    "    z = x[3*num_coeffs:]\n",
    "    dz = derivative(z, dt=dt)\n",
    "    z = z.reshape(1, z.shape[0]) # reshape so we can concatenate with x_trunc\n",
    "    library = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    x_est = np.concatenate((x_trunc, z.T), axis=1)\n",
    "    Theta = library.fit_transform(x_est)\n",
    "    A = block_diag(Theta, Theta, Theta)\n",
    "    dx_est = np.concatenate((dx_trunc, dz), axis=1)\n",
    "    dx_est = dx_est.ravel()\n",
    "    rows = A @ coeffs - dx_est\n",
    "    if iter_num % 50000 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, np.sum(rows ** 2)))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return np.sum(rows ** 2)\n",
    "\n",
    "for _ in range(5):\n",
    "    res = minimize(f, x0, options={'maxiter': 10**6})\n",
    "    coeffs = res.x[:3*num_coeffs]\n",
    "    xmax = abs(coeffs[np.nonzero(coeffs)]).mean()\n",
    "    to_remove = [k for k in range(len(coeffs)) if abs(coeffs[k]) < l1*xmax]\n",
    "    for k in to_remove:\n",
    "        coeffs[k] = 0\n",
    "    x0 = np.zeros(3*num_coeffs + x.shape[0])\n",
    "    x0[:3*num_coeffs] = coeffs\n",
    "    iter_num = 0\n",
    "    print('Restarting process after removing extraneous coefficients...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0, residual is 1348848196.129323\n",
      "On iteration 50000, residual is 1162778346.9763827\n",
      "On iteration 100000, residual is 960713269.3101199\n",
      "On iteration 150000, residual is 1043859532.2567276\n",
      "On iteration 200000, residual is 1027286301.0323706\n",
      "On iteration 250000, residual is 920962144.9298322\n",
      "On iteration 300000, residual is 979036880.4716467\n",
      "On iteration 350000, residual is 930071555.828321\n",
      "On iteration 400000, residual is 910738347.7205751\n",
      "On iteration 450000, residual is 808974709.3207011\n",
      "On iteration 500000, residual is 812081513.5436177\n",
      "On iteration 550000, residual is 967615841.9073381\n",
      "On iteration 600000, residual is 754520452.0790766\n",
      "On iteration 650000, residual is 838309615.6839061\n",
      "On iteration 700000, residual is 633643557.9302995\n",
      "On iteration 750000, residual is 796136399.5904694\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to zero\n",
    "bounds = [(-5, 5)] * (3*num_coeffs + x.shape[0])\n",
    "l1 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "res = differential_evolution(f, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
