{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz System with Missing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Simulating the Lorenz system.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lorenz import Lorenz\n",
    "\n",
    "# --> Sets the parameters to their classical values.\n",
    "sigma, rho, beta = 10., 28., 8./3.\n",
    "\n",
    "# --> Integration time.\n",
    "t = np.linspace(0, 20, 2000)\n",
    "\n",
    "# --> Produce the date to be used in the sparse identification.\n",
    "x0 = np.array([-8., 7., 27.]) # Initial condition.\n",
    "x, dx = Lorenz(x0, sigma, rho, beta, t)\n",
    "\n",
    "# --> Slightly different initial condition to highlight the chaotic nature.\n",
    "y0 = np.array([-8.01, 7., 27.]) # Initial condition.\n",
    "y, dy = Lorenz(y0, sigma, rho, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Plot time traces of the two trajectories as well as the corresponding stange attractor.\n",
    "w = 10\n",
    "fig = plt.figure(figsize=(1.5*w, w/2))\n",
    "gs = GridSpec(3, 6)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0, :3])\n",
    "ax0.plot(t, x[:, 0])\n",
    "ax0.plot(t, y[:, 0])\n",
    "ax0.set_ylabel('x')\n",
    "ax0.set_xticks([])\n",
    "ax0.set_xlim(0, 20)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1, :3])\n",
    "ax1.plot(t, x[:, 1])\n",
    "ax1.plot(t, y[:, 1])\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xlim(0, 20)\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2, :3])\n",
    "ax2.plot(t, x[:, 2])\n",
    "ax2.plot(t, y[:, 2])\n",
    "ax2.set_ylabel('z')\n",
    "ax2.set_xlabel('t')\n",
    "ax2.set_xlim(0, 20)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[:, 3:], projection='3d')\n",
    "ax3.plot(x[:, 0], x[:, 1], x[:, 2])\n",
    "ax3.plot(y[:, 0], y[:, 1], y[:, 2])\n",
    "ax3.set_xlabel('x', labelpad=10)\n",
    "ax3.set_ylabel('y')\n",
    "ax3.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Creation of the library Theta.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "library = PolynomialFeatures(degree=2, include_bias=True)\n",
    "Theta = library.fit_transform(x)\n",
    "n_lib = library.n_output_features_\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "A = block_diag(Theta, Theta, Theta)\n",
    "b = dx.flatten(order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Sequentially hard-thresholded estimator.\n",
    "from sparse_identification import sindy\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "shols = sindy(l1=0.01, solver='lstsq')\n",
    "\n",
    "# --> Fit the OLS model.\n",
    "shols.fit(A, b)\n",
    "print('Total number of possible terms :', shols.coef_.size)\n",
    "print('Number of non-zero coefficients :', np.count_nonzero(shols.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identified equation for x : \\n\")\n",
    "print(shols.coef_[:n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[n_lib:2*n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[2*n_lib:3*n_lib], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "library = PolynomialFeatures(degree=5, include_bias=True)\n",
    "Theta = library.fit_transform(x_trunc)\n",
    "n_lib = library.n_output_features_\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "A_trunc = block_diag(Theta, Theta)\n",
    "b_trunc = dx_trunc.flatten(order='F')\n",
    "\n",
    "shols_trunc = sindy(l1=0.01, solver='lstsq')\n",
    "\n",
    "# --> Fit the OLS model to truncated data\n",
    "shols_trunc.fit(A_trunc, b_trunc)\n",
    "print('Total number of possible terms :', shols_trunc.coef_.size)\n",
    "print('Number of non-zero coefficients :', np.count_nonzero(shols_trunc.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Identified equation for x : \\n\")\n",
    "print(shols.coef_[:n_lib], \"\\n\")\n",
    "print(\"\\n Identified equation for y : \\n\")\n",
    "print(shols.coef_[n_lib:2*n_lib], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Algorithm for Missing Variables applied to Lorenz System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Simulating the Lorenz system.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lorenz import Lorenz\n",
    "\n",
    "# --> Sets the parameters to their classical values.\n",
    "sigma, rho, beta = 10., 28., 8./3.\n",
    "\n",
    "# --> Integration time.\n",
    "t = np.linspace(0, 20, 2000)\n",
    "\n",
    "# --> Produce the date to be used in the sparse identification.\n",
    "x0 = np.array([-8., 7., 27.]) # Initial condition.\n",
    "x, dx = Lorenz(x0, sigma, rho, beta, t)\n",
    "\n",
    "# --> Slightly different initial condition to highlight the chaotic nature.\n",
    "y0 = np.array([-8.01, 7., 27.]) # Initial condition.\n",
    "y, dy = Lorenz(y0, sigma, rho, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "dt = t[1] - t[0]\n",
    "degree = 2\n",
    "num_coeffs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to zero\n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def f(x):\n",
    "    global iter_num\n",
    "    coeffs = x[:3*num_coeffs]\n",
    "    z = x[3*num_coeffs:]\n",
    "    dz = derivative(z, dt=dt)\n",
    "    z = z.reshape(1, z.shape[0]) # reshape so we can concatenate with x_trunc\n",
    "    library = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    x_est = np.concatenate((x_trunc, z.T), axis=1)\n",
    "    Theta = library.fit_transform(x_est)\n",
    "    A = block_diag(Theta, Theta, Theta)\n",
    "    dx_est = np.concatenate((dx_trunc, dz), axis=1)\n",
    "    dx_est = dx_est.ravel()\n",
    "    rows = A @ coeffs - dx_est\n",
    "    if iter_num % 50000 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, np.sum(rows ** 2)))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return np.sum(rows ** 2)\n",
    "\n",
    "res = minimize(f, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import basinhopping\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to one\n",
    "l1 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "res = basinhopping(f, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Algorithm for Missing Variables applied to Lotka-Volterra System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the Lotka-Volterra system\n",
    "\\begin{align*}\n",
    "\\dot{x} &= x(1 - y) \\\\\n",
    "\\dot{y} &= y(-1 + x - z) \\\\\n",
    "\\dot{z} &= z(-1 + y)\n",
    "\\end{align*}\n",
    "with initial conditions $[x(0), y(0), z(0)] = [0.5, 1, 2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lotka_Volterra import Lotka_Volterra\n",
    "\n",
    "alpha = np.array([1, -1, -1])\n",
    "beta = np.array([[0, -1, 0], [1, 0, -1], [0, 1, 0]])\n",
    "t = np.linspace(0, 5, 2000)\n",
    "x0 = np.array([0.5, 1, 2]) # Initial condition.\n",
    "x, dx = Lotka_Volterra(x0, alpha, beta, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "dx_trunc = x[:, :2]\n",
    "dt = t[1] - t[0]\n",
    "l1 = 0.01\n",
    "degree = 2\n",
    "num_coeffs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below algorithm, we treat the values of $z(t_k)$ and the coefficients as unknown variables, and we try to solve using non-linear optimization on the sum of squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "x0 = np.zeros(3*num_coeffs + x.shape[0]) # initialize starting values to zero\n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def f(x):\n",
    "    global iter_num\n",
    "    coeffs = x[:3*num_coeffs]\n",
    "    z = x[3*num_coeffs:]\n",
    "    dz = derivative(z, dt=dt)\n",
    "    z = z.reshape(1, z.shape[0]) # reshape so we can concatenate with x_trunc\n",
    "    library = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    x_est = np.concatenate((x_trunc, z.T), axis=1)\n",
    "    Theta = library.fit_transform(x_est)\n",
    "    A = block_diag(Theta, Theta, Theta)\n",
    "    dx_est = np.concatenate((dx_trunc, dz), axis=1)\n",
    "    dx_est = dx_est.ravel()\n",
    "    rows = A @ coeffs - dx_est\n",
    "    if iter_num % 50000 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, np.sum(rows ** 2)))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return np.sum(rows ** 2)\n",
    "\n",
    "for _ in range(5):\n",
    "    res = minimize(f, x0, options={'maxiter': 10**6})\n",
    "    coeffs = res.x[:3*num_coeffs]\n",
    "    xmax = abs(coeffs[np.nonzero(coeffs)]).mean()\n",
    "    to_remove = [k for k in range(len(coeffs)) if abs(coeffs[k]) < l1*xmax]\n",
    "    for k in to_remove:\n",
    "        coeffs[k] = 0\n",
    "    x0 = np.zeros(3*num_coeffs + x.shape[0])\n",
    "    x0[:3*num_coeffs] = coeffs\n",
    "    iter_num = 0\n",
    "    print('Restarting process after removing extraneous coefficients...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above algorithm was not successful. We modify it to instead only treat the coefficients and the starting value $z(t_0)$ as unknowns, and use a numerical solver to determine the values of $x, y, z$ at each point $t_k$ in time. After this, we use the non-linear optimization again to solve the least squares problem for the predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "x0 = [1e-3] * (3*num_coeffs + 1) # initialize coefficients to be small values \n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "library = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "\n",
    "def system_vals(y0, t, coeffs):\n",
    "    Theta = library.fit_transform([y0])\n",
    "    A = block_diag(Theta, Theta, Theta)\n",
    "    return A @ coeffs\n",
    "\n",
    "def f(y):\n",
    "    global iter_num\n",
    "    coeffs = y[:3*num_coeffs]\n",
    "    z_start = y[-1]\n",
    "    initial = [x_trunc[0, 0], x_trunc[0, 1], z_start]\n",
    "    x_est = odeint(system_vals, initial, t, args=(coeffs,))\n",
    "    x_est = x_est[:, :2] # only keep first two columns so we can compare with actual values\n",
    "    diff_sq = np.sum((x_trunc - x_est) ** 2)\n",
    "    if iter_num % 100 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, diff_sq))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return diff_sq\n",
    "\n",
    "for _ in range(5):\n",
    "    res = minimize(f, x0)\n",
    "    print('Result after this step:')\n",
    "    pprint(res.x)\n",
    "    coeffs = res.x[:3*num_coeffs]\n",
    "    for i in range(3):\n",
    "        coeff_block = coeffs[i*num_coeffs:(i+1)*num_coeffs]\n",
    "        xmax = abs(coeff_block[np.nonzero(coeff_block)]).mean()\n",
    "        to_remove = [k for k in range(len(coeff_block)) if abs(coeff_block[k]) < l1*xmax]\n",
    "        for k in to_remove:\n",
    "            coeffs[i*num_coeffs + k] = 0\n",
    "    x0 = np.zeros(3*num_coeffs + 1)\n",
    "    x0[:3*num_coeffs] = coeffs\n",
    "    x0[-1] = res.x[-1]\n",
    "    iter_num = 0\n",
    "    print('Restarting process after removing extraneous coefficients...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above converged to a residual of 0.01, but the coefficients were wildly off those of the original system. It may be the case that there are too many local minima present for the algorithm to work well in the general case. We next constrain the polynomial terms in each system to only be those of the Lotka-Volterra system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case where one of the variables is missing\n",
    "x_trunc = x[:, :2]\n",
    "l1 = 0.01\n",
    "num_coeffs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sparse_identification.utils import derivative\n",
    "\n",
    "num_coeffs = 4 # Each Lotka-Volterra system has at most four nonzero coefficients\n",
    "x0 = [1e-3] * (3*num_coeffs + 1) # initialize coefficients to be small values \n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def make_terms(y):\n",
    "    # make the polynomial terms of the Lotka-Volterra system\n",
    "    terms = []\n",
    "    base = np.concatenate(([1], y))\n",
    "    for i in range(len(y)):\n",
    "        terms.append(y[i] * base)\n",
    "    return np.array(terms)\n",
    "\n",
    "def system_vals(y0, t, coeffs):\n",
    "    terms = make_terms(y0)\n",
    "    A = block_diag(*terms)\n",
    "    return A @ coeffs\n",
    "\n",
    "def f(y):\n",
    "    global iter_num\n",
    "    coeffs = y[:3*num_coeffs]\n",
    "    z_start = y[-1]\n",
    "    initial = [x_trunc[0, 0], x_trunc[0, 1], z_start]\n",
    "    x_est = odeint(system_vals, initial, t, args=(coeffs,))\n",
    "    x_est = x_est[:, :2] # only keep first two columns so we can compare with actual values\n",
    "    diff_sq = np.sum((x_trunc - x_est) ** 2)\n",
    "    if iter_num % 100 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, diff_sq))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return diff_sq\n",
    "\n",
    "for _ in range(5):\n",
    "    res = minimize(f, x0)\n",
    "    print('Result after this step:')\n",
    "    pprint(res.x)\n",
    "    coeffs = res.x[:3*num_coeffs]\n",
    "    for i in range(3):\n",
    "        coeff_block = coeffs[i*num_coeffs:(i+1)*num_coeffs]\n",
    "        xmax = abs(coeff_block[np.nonzero(coeff_block)]).mean()\n",
    "        to_remove = [k for k in range(len(coeff_block)) if abs(coeff_block[k]) < l1*xmax]\n",
    "        for k in to_remove:\n",
    "            coeffs[i*num_coeffs + k] = 0\n",
    "    x0 = np.zeros(3*num_coeffs + 1)\n",
    "    x0[:3*num_coeffs] = coeffs\n",
    "    x0[-1] = res.x[-1]\n",
    "    iter_num = 0\n",
    "    print('Restarting process after removing extraneous coefficients...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2 = np.array([0.9982, -0.9774, -0.9531])\n",
    "beta2 = np.array([[0, -1.00015232, 0.00813716], [0.99634992, 0, -7.23730658], [-0.01271289, 0.99328139, -0.13339578]])\n",
    "t = np.linspace(0, 5, 2000)\n",
    "x0_2 = np.array([0.5, 1, 2.79314641e-01]) # Initial condition.\n",
    "x2, dx2 = Lotka_Volterra(x0_2, alpha2, beta2, t)\n",
    "np.max(x2 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove the variable $z$ ad use the above algorithm, we get the system\n",
    "\\begin{align*}\n",
    "\\dot{x} &= x(9.98188683 \\cdot 10^{-1} + 5.02546447 \\cdot 10^{-4}x - 1.00015232y + 8.13716153 \\cdot 10^{-3}z) \\\\\n",
    "\\dot{y} &= y(-9.77408801 \\cdot 10^{-1} + 9.96349918 \\cdot 10^{-1}x - 1.99183904 \\cdot 10^{-3}y - 7.23730658z) \\\\\n",
    "\\dot{z} &= z(-9.53057554 \\cdot 10^{-2} -1.27128901 \\cdot 10^{-2}x + 9.93281392 \\cdot 10^{-1}y  -1.33395777 \\cdot 10^{-1}z)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case where points are not uniformly spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0, residual is 12254.118984709741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/integrate/odepack.py:218: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/alexander/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/integrate/odepack.py:218: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 100, residual is 8471.399130842643\n",
      "On iteration 200, residual is 5525.529300035295\n",
      "On iteration 300, residual is 5222.3849415461555\n",
      "On iteration 400, residual is 5034.702914483738\n",
      "On iteration 500, residual is 2430.697010403767\n",
      "On iteration 600, residual is 1068.2643094485215\n",
      "On iteration 700, residual is 526.5980277289565\n",
      "On iteration 800, residual is 248.93720354585147\n",
      "On iteration 900, residual is 154.7133648505452\n",
      "On iteration 1000, residual is 127.54704381644855\n",
      "On iteration 1100, residual is 83.30354202342684\n",
      "On iteration 1200, residual is 75.69913313850574\n",
      "On iteration 1300, residual is 58.65713379490886\n",
      "On iteration 1400, residual is 53.13884365802938\n",
      "On iteration 1500, residual is 33.80745572226184\n",
      "On iteration 1600, residual is 9.893257230863508\n",
      "On iteration 1700, residual is 6.455049992087265\n",
      "On iteration 1800, residual is 3.978599264745843\n",
      "On iteration 1900, residual is 1.3169097186866559\n",
      "On iteration 2000, residual is 0.5655804301883887\n",
      "On iteration 2100, residual is 0.2563605546284632\n",
      "On iteration 2200, residual is 0.15219548672121663\n",
      "On iteration 2300, residual is 5.87325965293686e-07\n",
      "On iteration 2400, residual is 1.3401688083313464e-08\n",
      "On iteration 2500, residual is 1.3436188478898987e-08\n",
      "On iteration 2600, residual is 1.3400420764907171e-08\n",
      "On iteration 2700, residual is 1.3442963495315185e-08\n",
      "On iteration 2800, residual is 1.3442673590686385e-08\n",
      "On iteration 2900, residual is 1.3438093893731794e-08\n",
      "On iteration 3000, residual is 1.3405143310357134e-08\n",
      "On iteration 3100, residual is 1.3401253736077428e-08\n",
      "On iteration 3200, residual is 1.3436188477071398e-08\n",
      "On iteration 3300, residual is 1.3400420780928887e-08\n",
      "On iteration 3400, residual is 1.3442963492195384e-08\n",
      "Result after this step:\n",
      "array([  1.00002093e+00,  -5.80465408e-06,  -9.99997968e-01,\n",
      "        -1.36925914e-05,  -1.00001300e+00,   1.00000525e+00,\n",
      "         2.19542162e-08,  -9.99996401e-01,  -9.99992414e-01,\n",
      "        -2.08966185e-06,   1.00000035e+00,  -3.56012131e-06])\n",
      "Restarting process after removing extraneous coefficients...\n",
      "On iteration 0, residual is 0.00010966977533411436\n",
      "On iteration 100, residual is 8.435662718448705e-08\n",
      "On iteration 200, residual is 1.844342420001732e-08\n",
      "On iteration 300, residual is 1.8496126030489146e-08\n",
      "On iteration 400, residual is 1.836575651222925e-08\n",
      "On iteration 500, residual is 1.8488243278979157e-08\n",
      "On iteration 600, residual is 1.8481175904276673e-08\n",
      "On iteration 700, residual is 1.8530061987471682e-08\n",
      "On iteration 800, residual is 1.846790668085282e-08\n",
      "On iteration 900, residual is 1.843466063336678e-08\n",
      "On iteration 1000, residual is 1.8496058131088e-08\n",
      "On iteration 1100, residual is 1.8365832922112075e-08\n",
      "On iteration 1200, residual is 1.8488243278979157e-08\n",
      "On iteration 1300, residual is 1.8443853951834904e-08\n",
      "Result after this step:\n",
      "array([  1.00001395e+00,  -3.54850459e-06,  -9.99998812e-01,\n",
      "        -9.94220630e-06,  -1.00001296e+00,   1.00000531e+00,\n",
      "        -7.09585110e-07,  -9.99996228e-01,  -9.99994405e-01,\n",
      "        -7.05051504e-07,   9.99999635e-01,  -3.66591947e-06])\n",
      "Restarting process after removing extraneous coefficients...\n",
      "On iteration 0, residual is 5.031363278691974e-05\n",
      "On iteration 100, residual is 3.526581097019525e-08\n",
      "On iteration 200, residual is 4.588993845231499e-09\n",
      "On iteration 300, residual is 4.584480475510251e-09\n",
      "On iteration 400, residual is 4.592829938485679e-09\n",
      "On iteration 500, residual is 4.576421468692987e-09\n",
      "On iteration 600, residual is 4.579617010987096e-09\n",
      "On iteration 700, residual is 4.583798824776422e-09\n",
      "On iteration 800, residual is 4.614056010609755e-09\n",
      "On iteration 900, residual is 4.5889831204144885e-09\n",
      "Result after this step:\n",
      "array([  1.00001062e+00,  -3.21750189e-06,  -9.99998741e-01,\n",
      "        -6.74756759e-06,  -1.00001278e+00,   1.00000452e+00,\n",
      "         3.95210130e-07,  -9.99995809e-01,  -9.99995735e-01,\n",
      "        -1.12849115e-06,   1.00000022e+00,  -2.04604218e-06])\n",
      "Restarting process after removing extraneous coefficients...\n",
      "On iteration 0, residual is 2.9762870142177127e-05\n",
      "On iteration 100, residual is 2.2387612843240784e-08\n",
      "On iteration 200, residual is 3.2792415214936054e-09\n",
      "On iteration 300, residual is 3.237668940351258e-09\n",
      "On iteration 400, residual is 3.243916399588831e-09\n",
      "On iteration 500, residual is 3.22605960479926e-09\n",
      "On iteration 600, residual is 3.224905814331179e-09\n",
      "On iteration 700, residual is 3.2380693933504133e-09\n",
      "On iteration 800, residual is 3.22704256229665e-09\n",
      "Result after this step:\n",
      "array([  1.00000741e+00,  -2.43547162e-06,  -9.99998778e-01,\n",
      "        -4.61482695e-06,  -1.00001270e+00,   1.00000436e+00,\n",
      "         4.83933917e-07,  -9.99995627e-01,  -9.99996671e-01,\n",
      "        -7.43072201e-07,   9.99999830e-01,  -1.53221817e-06])\n",
      "Restarting process after removing extraneous coefficients...\n",
      "On iteration 0, residual is 1.5301567282430664e-05\n",
      "On iteration 100, residual is 1.1682548608281113e-08\n",
      "On iteration 200, residual is 2.6550745235241226e-09\n",
      "On iteration 300, residual is 2.652566704630575e-09\n",
      "On iteration 400, residual is 2.6519616397699734e-09\n",
      "On iteration 500, residual is 2.6535947255580334e-09\n",
      "On iteration 600, residual is 2.6579161135825557e-09\n",
      "Result after this step:\n",
      "array([  1.00000533e+00,  -1.93065860e-06,  -9.99998838e-01,\n",
      "        -3.22061735e-06,  -1.00001262e+00,   1.00000424e+00,\n",
      "         4.96966638e-07,  -9.99995514e-01,  -9.99997353e-01,\n",
      "        -4.94339216e-07,   9.99999698e-01,  -1.14839665e-06])\n",
      "Restarting process after removing extraneous coefficients...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from Lotka_Volterra import Lotka_Volterra\n",
    "\n",
    "alpha = np.array([1, -1, -1])\n",
    "beta = np.array([[0, -1, 0], [1, 0, -1], [0, 1, 0]])\n",
    "# choose points that are not uniformly spaced\n",
    "t = np.sort(np.random.uniform(0, 5, 2000))\n",
    "x0 = np.array([0.5, 1, 2]) # Initial condition.\n",
    "x, dx = Lotka_Volterra(x0, alpha, beta, t)\n",
    "l1 = 0.01\n",
    "degree = 2\n",
    "num_coeffs = 4\n",
    "\n",
    "x0 = [1e-3] * (3*num_coeffs) # initialize coefficients to be small values \n",
    "l2 = 0.01\n",
    "iter_num = 0\n",
    "\n",
    "def make_terms(y):\n",
    "    # make the polynomial terms of the Lotka-Volterra system\n",
    "    terms = []\n",
    "    base = np.concatenate(([1], y))\n",
    "    for i in range(len(y)):\n",
    "        terms.append(y[i] * base)\n",
    "    return np.array(terms)\n",
    "\n",
    "def system_vals(y0, t, coeffs):\n",
    "    terms = make_terms(y0)\n",
    "    A = block_diag(*terms)\n",
    "    return A @ coeffs\n",
    "\n",
    "def f(y):\n",
    "    global iter_num\n",
    "    initial = x[0]\n",
    "    x_est = odeint(system_vals, initial, t, args=(y,))\n",
    "    diff_sq = np.sum((x - x_est) ** 2)\n",
    "    if iter_num % 100 == 0:\n",
    "        print('On iteration {}, residual is {}'.format(iter_num, diff_sq))\n",
    "    iter_num += 1\n",
    "    \n",
    "    return diff_sq\n",
    "\n",
    "for _ in range(5):\n",
    "    res = minimize(f, x0)\n",
    "    print('Result after this step:')\n",
    "    pprint(res.x)\n",
    "    coeffs = res.x\n",
    "    for i in range(3):\n",
    "        coeff_block = coeffs[i*num_coeffs:(i+1)*num_coeffs]\n",
    "        xmax = abs(coeff_block[np.nonzero(coeff_block)]).mean()\n",
    "        to_remove = [k for k in range(len(coeff_block)) if abs(coeff_block[k]) < l1*xmax]\n",
    "        for k in to_remove:\n",
    "            coeffs[i*num_coeffs + k] = 0\n",
    "    x0 = coeffs\n",
    "    iter_num = 0\n",
    "    print('Restarting process after removing extraneous coefficients...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
